{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb9698",
   "metadata": {},
   "source": [
    "# Flightops - Data Acquisition, Loading and Pre-processing\n",
    "\n",
    "## Extracting Data from BTS\n",
    "Flight data for 2018â€“2019 is sourced from the BTS TranStats repository using an automated downloader script:\n",
    "- `download_bts_ontime.py` fetches monthly On-Time Performance files and extracts them into the project directory.\n",
    "- Run this command from the repo root to download the necessary files: *python download_bts_ontime.py*\n",
    "\n",
    "## Load, and Clean Data\n",
    "\n",
    "Data cleaning is one of the most critical (and usually most tedious) part of data analysis. But the effort is always worth it because, as the old saying goes, **garbage in, garbage out!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f86cb1",
   "metadata": {},
   "source": [
    "environment: conda activate datasci311"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c3b85",
   "metadata": {},
   "source": [
    "### Set stable root directory for relative paths in VSCode\n",
    "\n",
    "VS Code + Jupyter has notoriously unstable CWDs because it is flexible in where it runs notebooks from (e.g. the workspace root, a previously cached directory, a kernel opened *before* the repo was opened...). It's great that VSC has this flexibility, but it presents a weakness when making repos available in CI/GitHub. I've removed the ambiguity by controlling the CWD to make relative paths stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54be57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Establish repo root (notebooks live one level down)\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data/raw/csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e10418",
   "metadata": {},
   "source": [
    "### Load and Concatenate Files\n",
    "\n",
    "After extracting the required files from BTS, we'll load and combine them into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 CSV files.\n"
     ]
    }
   ],
   "source": [
    "files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "print(f\"Found {len(files)} CSV files.\") # used for visibility when debugging cwd issues\n",
    "\n",
    "# Specify columns to load to save memory, reducing columns loaded from 110 to 30 and dataframe memory usage from ~24.8 GB to ~11.1 GB\n",
    "usecols = [\n",
    "    # Date / identifiers\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"DayofMonth\",\n",
    "    \"DayOfWeek\",\n",
    "    \"FlightDate\",\n",
    "    \"Reporting_Airline\",\n",
    "    \"IATA_CODE_Reporting_Airline\",\n",
    "    \"Flight_Number_Reporting_Airline\",\n",
    "    \"Tail_Number\",\n",
    "\n",
    "    # Origin / destination\n",
    "    \"Origin\",\n",
    "    \"OriginCityName\",\n",
    "    \"OriginState\",\n",
    "    \"Dest\",\n",
    "    \"DestCityName\",\n",
    "    \"DestState\",\n",
    "\n",
    "    # Scheduled vs actual times\n",
    "    \"CRSDepTime\",\n",
    "    \"CRSArrTime\",\n",
    "    \"DepTime\",\n",
    "    \"ArrTime\",\n",
    "\n",
    "    # Delay metrics\n",
    "    \"DepDelay\",\n",
    "    \"DepDelayMinutes\",\n",
    "    \"DepDel15\",\n",
    "    \"ArrDelay\",\n",
    "    \"ArrDelayMinutes\",\n",
    "    \"ArrDel15\",\n",
    "\n",
    "    # Status flags\n",
    "    \"Cancelled\",\n",
    "    \"Diverted\",\n",
    "    \"CancellationCode\",\n",
    "\n",
    "    # Distance / throughput\n",
    "    \"Distance\",\n",
    "    \"Flights\",\n",
    "]\n",
    "\n",
    "# Adding a dtype map to reduce memory usage further\n",
    "dtypes = {\n",
    "    \"Year\": \"int16\",\n",
    "    \"Month\": \"int8\",\n",
    "    \"DayofMonth\": \"int8\",\n",
    "    \"DayOfWeek\": \"int8\",\n",
    "    \"Reporting_Airline\": \"category\",\n",
    "    \"IATA_CODE_Reporting_Airline\": \"category\",\n",
    "    \"Tail_Number\": \"category\",\n",
    "    \"Flight_Number_Reporting_Airline\": \"int32\",\n",
    "    \"Origin\": \"category\",\n",
    "    \"OriginCityName\": \"category\",\n",
    "    \"OriginState\": \"category\",\n",
    "    \"Dest\": \"category\",\n",
    "    \"DestCityName\": \"category\",\n",
    "    \"DestState\": \"category\",\n",
    "    \"CRSDepTime\": \"int32\",\n",
    "    \"CRSArrTime\": \"int32\",\n",
    "    \"DepTime\": \"float32\",\n",
    "    \"ArrTime\": \"float32\",\n",
    "    \"DepDelay\": \"float32\",\n",
    "    \"DepDelayMinutes\": \"float32\",\n",
    "    \"DepDel15\": \"Int8\",\n",
    "    \"ArrDelay\": \"float32\",\n",
    "    \"ArrDelayMinutes\": \"float32\",\n",
    "    \"ArrDel15\": \"Int8\",\n",
    "    \"Cancelled\": \"Int8\",\n",
    "    \"Diverted\": \"Int8\",\n",
    "    \"CancellationCode\": \"category\",\n",
    "    \"Distance\": \"float32\",\n",
    "    \"Flights\": \"Int8\",\n",
    "}\n",
    "\n",
    "dfs = [pd.read_csv(f, low_memory=False, usecols=usecols, dtype=dtypes) for f in files]\n",
    "\n",
    "flights = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef8cb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14628232, np.float64(8.14171683229506))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights), flights.memory_usage(deep=True).sum() / (1024**3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b88aa",
   "metadata": {},
   "source": [
    "#### Find TranStats terminology at:\n",
    "[BTS Table Info](https://www.transtats.bts.gov/TableInfo.asp?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr&V0s1_b0yB=D)\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "BTS column names are in all caps, with mixed formatting, so we'll strip out white space and special characters and replace spaces and hyphens with underscores for standard Python-friendly formatting.\n",
    "\n",
    "Additionally, these BTS tables report on cancelled and diverted flights. This data will distort KPIs like average delay and on-time rates because they do not have meaningful arrival delay values. Therefore, we will filter them out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bbbb6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'month', 'dayofmonth', 'dayofweek', 'flightdate', 'reporting_airline', 'iata_code_reporting_airline', 'tail_number', 'flight_number_reporting_airline', 'origin', 'origincityname', 'originstate', 'dest', 'destcityname', 'deststate', 'crsdeptime', 'deptime', 'depdelay', 'depdelayminutes', 'depdel15', 'crsarrtime', 'arrtime', 'arrdelay', 'arrdelayminutes', 'arrdel15', 'cancelled', 'cancellationcode', 'diverted', 'flights', 'distance']\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names\n",
    "\n",
    "flights.columns = (\n",
    "    flights.columns.str.strip()  # Remove leading/trailing whitespace\n",
    "        .str.lower()  # Lowercase all characters\n",
    "        .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "print(flights.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7381d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: can we treat missing flags as 0/1?\n",
    "\n",
    "flights[\"cancelled\"].value_counts(dropna=False).head()\n",
    "flights[\"diverted\"].value_counts(dropna=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing flags as 0/1, removing any NaNs that may interfere with filtering\n",
    "\n",
    "flag_cols = [\"cancelled\", \"diverted\", \"depdel15\", \"arrdel15\", \"flights\"]\n",
    "for c in flag_cols:\n",
    "    flights[c] = flights[c].fillna(0).astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c854cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 14628232\n",
      "Rows after cleaning: 14340046\n"
     ]
    }
   ],
   "source": [
    "# Filter Cancelled/Diverted Flights\n",
    "\n",
    "flights_clean = flights[\n",
    "    (flights['cancelled'] == 0) &\n",
    "    (flights['diverted'] == 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Rows before cleaning: {len(flights)}\")\n",
    "print(f\"Rows after cleaning: {len(flights_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794f395",
   "metadata": {},
   "source": [
    "<mark>personal note</mark>\n",
    "\n",
    ".copy() uses a lot of RAM. Flights currently uses ~8G memory, which pushes to 16G when executing above code. If more issues arise due to memory overhead (other apps open and using RAM), then use this code to filter with a mask, selected only needed columns, before you copy:\n",
    "\n",
    "mask = (flights[\"cancelled\"] == 0) & (flights[\"diverted\"] == 0)\n",
    "flights_clean = flights.loc[mask].copy()\n",
    "\n",
    "print(f\"Rows before cleaning: {len(flights):,}\")\n",
    "print(f\"Rows after cleaning:  {len(flights_clean):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e53581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete flights dataframe to free up memory (and prevent crashes during modeling)\n",
    "del flights\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b0a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4cfda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ac5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b3beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda: datasci311",
   "language": "python",
   "name": "datasci311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
